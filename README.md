# Agent-robotic-foundation-model

## üë©‚Äçüíª Maintainers / Contributors

| Name | Role | Affiliation |
|------|------|-------------|
| **<a href="https://dr-lingxiao.github.io/" target="_blank" rel="noopener">Ling Xiao</a>** | Principal Investigator / Project Lead | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |
| **Xinyu Zhang** | D1 / Multimodal Navigation | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |
| **Tomohito Kawabata** | B4 / Multimodal Navigation | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |
| **Zishuo Wang** | Research Student / Multimodal Navigation | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |
| **Zhuonan Liu** | Research Student / Multimodal Navigation | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |


## 1. Scene Perception & Human Intention Understanding
### üìÑ Representative Papers
[1]  Chen, Y., Zhang, I. G., Zhang, Y., Xu, H., Zhi, P., Li, Q., & Huang, S. (2025, May). *Synergai: Perception alignment for human-robot collaboration.* [[ICRA]](https://ieeexplore.ieee.org/abstract/document/11128658/) <br>
[2]  Xu, W., Zhou, T., Zhang, T., Li, J., Chen, P., Pan, J., & Liu, X. (2025). *Exploring Grounding Abilities in Vision-Language Models through Contextual Perception*. [[IEEE Transactions on Cognitive and Developmental Systems]] (https://ieeexplore.ieee.org/abstract/document/10985830) <br>
[3]  <br>


---

## 2. LLM-guided Socially Compliant Navigation.
### üìÑ Representative Papers
[1] Payandeh, A., Song, D., Nazeri, M., Liang, J., Mukherjee, P., Raj, A. H., ... & Xiao, X. (2024). *Social-LLaVA: Enhancing robot navigation through human-language reasoning in social spaces.* [[arXiv]](https://arxiv.org/abs/2501.09024) <br>
[2] Kong, Y., Song, D., Liang, J., Manocha, D., Yao, Z., & Xiao, X. (2024). *AutoSpatial: Visual-Language Reasoning for Social Robot Navigation through Efficient Spatial Reasoning Learning.* [[arXiv]](https://arxiv.org/abs/2503.07557) <br>
[3] Munje, M. J., Tang, C., Liu, S., Hu, Z., Zhu, Y., Cui, J., ... & Stone, P. (2025). *Socialnav-SUB: Benchmarking VLMs for scene understanding in social robot navigation.* [[arXiv]](https://arxiv.org/abs/2509.08757) <br>
[4]   <br>
[5]   <br>


---

## 3. Human‚ÄìRobot Interaction (HRI)
### üìÑ Representative Papers
[1] Han, L., Min, H., Hwangbo, G., Choi, J., & Seo, P. H. (2025). *DialNav: Multi-turn Dialog Navigation with a Remote Guide.* [[arXiv]](https://arxiv.org/abs/2509.12894)  <br>
[2]   <br>
[3]   <br>
[4]   <br>


---

## 4. Open-world Navigation
### üìÑ Representative Papers
[1] Shah, D., Osinski, B., Ichter, B., & Levine, S. (2022). *LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action.* [[arXiv]](https://arxiv.org/abs/2501.09024) <br>
[2]  <br>
[3]  <br>
[4]  <br>


---

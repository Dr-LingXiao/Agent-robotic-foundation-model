# Agent-robotic-foundation-model

## ğŸ‘©â€ğŸ’» Maintainers / Contributors

| Name | Role | Affiliation |
|------|------|-------------|
| **<a href="https://dr-lingxiao.github.io/" target="_blank" rel="noopener">Ling Xiao</a>** | Principal Investigator / Project Lead | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |
| **Xinyu Zhang** | D1 / Multimodal Navigation | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |
| **Tomohito Kawabata** | B4 / Multimodal Navigation | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |
| **Zishuo Wang** | Research Student / Multimodal Navigation | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |
| **Zhuonan Liu** | Research Student / Multimodal Navigation | <a href="https://www.global.hokudai.ac.jp/" target="_blank" rel="noopener">Hokkaido University</a> |


## 1. Scene Perception & Human Intention Understanding
### ğŸ“„ Representative Papers
[1]  <br>
[2]   <br>
[3]  <br>


---

## 2. LLM-guided Socially Compliant Navigation.
### ğŸ“„ Representative Papers
[1] Payandeh, A., Song, D., Nazeri, M., Liang, J., Mukherjee, P., Raj, A. H., ... & Xiao, X. (2024). *Social-LLaVA: Enhancing robot navigation through human-language reasoning in social spaces.* [[arXiv]](https://arxiv.org/abs/2501.09024) <br>
[2] Kong, Y., Song, D., Liang, J., Manocha, D., Yao, Z., & Xiao, X. (2024). *AutoSpatial: Visual-Language Reasoning for Social Robot Navigation through Efficient Spatial Reasoning Learning.* [[arXiv]](https://arxiv.org/abs/2503.07557) <br>
[3] Munje, M. J., Tang, C., Liu, S., Hu, Z., Zhu, Y., Cui, J., ... & Stone, P. (2025). *Socialnav-SUB: Benchmarking VLMs for scene understanding in social robot navigation.* [[arXiv]](https://arxiv.org/abs/2509.08757) <br>
[4]   <br>
[5]   <br>


---

## 3. Humanâ€“Robot Interaction (HRI)
### ğŸ“„ Representative Papers
[1] Han, L., Min, H., Hwangbo, G., Choi, J., & Seo, P. H. (2025). *DialNav: Multi-turn Dialog Navigation with a Remote Guide.* [[arXiv]](https://arxiv.org/abs/2509.12894)  <br>
[2]   <br>
[3]   <br>
[4]   <br>


---

## 4. Open-world Navigation
### ğŸ“„ Representative Papers
[1] Shah, D., Osinski, B., Ichter, B., & Levine, S. (2022). *LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action.* [[arXiv]](https://arxiv.org/abs/2501.09024) <br>
[2]  <br>
[3]  <br>
[4]  <br>


---

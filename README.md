# Agent-robotic-foundation-model

## ğŸ‘©â€ğŸ’» Maintainers / Contributors

| Name | Role | Affiliation |
|------|------|-------------|
| **Ling Xiao** | Principal Investigator / Project Lead | Hokkaido University |
| **Xinyu Zhang** | D1 / Multimodal Navigation | Hokkaido University |
| **Tomohito Kawabata** | B4 / Multimodal Navigation | Hokkaido University |
| **Zishuo Wang** | Research Student / Multimodal Navigation | Hokkaido University |
| **Zhuonan Liu** | Research Student / Multimodal Navigation | Hokkaido University |


## 1. LLM-based Social Perception & Human Intention Understanding
LLMs for understanding humans, behaviors, intentions, and social context.

### ğŸ“„ Representative Papers
- *(To be added)*  
-  
-  

---

## 2. LLM-guided Socially Compliant Planning
Using LLMs for semantic reasoning, high-level rules, etiquette reasoning, and human-aware path planning.

### ğŸ“„ Representative Papers
- *(To be added)*  
-  
-  

---

## 3. LLM-enhanced Humanâ€“Robot Interaction (HRI)
LLMs for natural language interaction, clarification, intent communication, and explainable actions.
- *(To be added)*  
-  
-  

---
### ğŸ“„ Representative Papers
- *(To be added)*  
-  
-  

---

## 4. Real-World Deployment & System Challenges for LLM-based Navigation
Safety, robustness, hallucination mitigation, multi-modal fusion, and real-world deployment.

### ğŸ“„ Representative Papers
- *(To be added)*  
-  
-  

---
